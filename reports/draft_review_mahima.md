# Draft Review for Alana and Sam
##### By Mahima 

## Question:  What is your understanding of the experiment the team is replicating?  What question does it answer?  How clear is the team's explanation?

The team is replicating Paterson's Worm with NetworkX in Python, and then looking into two characteristics of this CA: the distribution of the worm's length, and the viability of modifying the box method to count the pattern's Fractal Method.
The team's explanation of what they are implementing is very clear, however I am still uncertain what question they are looking to answer aside from "is it possible to box-count the fractal dimension of Paterson's Work?" However, it is unclear whether they are asking any questions with regards to the real world application of this model. Why is it a worm?

## Methodology: Do you understand the methodology?  Does it make sense for the question?  Are there limitations you see that the team did not address?

The methodology of their process thusfar has been described clearly. It is easy to understand what each of the steps are and what they entail. It fits the initial question of implementing Paterson's worm well. I am curious what they plan for the methodology of their extension to be. 

## Results: Do you understand what the results are (not yet considering their interpretation)?  If they are presented graphically, are the visualizations effective?  Do all figures have labels on the axes and captions?

The screenshots of their worms are a good form for presenting them, and they also look like they match the result of the experiment they are replicating. These graphs are titled with their rule number as well as their name, which is an approriate label for them.

## Interpretation: Does the draft report interpret the results as an answer to the motivating question?  Does the argument hold water?

Because it is slightly unclear what the main question is, it is difficult to uage how effective their interpretation of the results is. They have included an analysis of the worms, with an explanation of how it was conducted, however I do not understand why this would be important.

## Replication: Are the results in the report consistent with the results from the original paper?  If so, how did the authors demonstrate that consistency?  Is it quantitative or qualitative?

The results of their experiment are consistent with those from the original paper. They have shown this by including a screenshot of their result  alongside a screenshot of the original paper's resulting graph.

## Extension: Does the report explain an extension to the original experiment clearly?  Can it answer an interesting question that the original experiment did not answer?

Yes, they are looking to explore methods of calculating a fractal dimention on a triangular graph. It is an interesting epxloration of the properties of Paterson's Worm.

## Progress: Is the team roughly where they should be at this point, with a replication that is substantially complete and an extension that is clearly defined and either complete or nearly so?

Yes, the team's replication looks to be complete and their extension is well defined, however it seems that they may not have started implementing their extension as of yet.

## Presentation: Is the report written in clear, concise, correct language?  Is it consistent with the audience and goals of the report?  Does it violate any of the recommendations in my style guide (Links to an external site.)?

The language of the report is clear and concise, and explains the concepts and methodology well to the audience. It does not violate the style guide. 

## Mechanics: Is the report in the right directory with the right file name?  Is it formatted professionally in Markdown?  Does it include a meaningful title and the full names of the authors?  Is the bibliography in an acceptable style? 

The report is under the correct file name, and formatted well in Markdown. The title and author names are complete with an appropriate bibliography.
